#!/usr/bin/env python3
"""
ä¿®å¤è„šæœ¬ï¼šå°†é¡¹ç›®ä¸­çš„ text-davinci-003 æ¨¡å‹æ›¿æ¢ä¸º gpt-3.5-turbo å¹¶æ›´æ–°ç›¸å…³å‡½æ•°è°ƒç”¨
"""

import os
import re

def fix_gpt_structure():
    """ä¿®å¤ gpt_structure.py ä¸­çš„æ¨¡å‹é…ç½®"""
    file_path = "/Users/gongyunbo/Documents/Github/generative_agents/reverie/backend_server/persona/prompt_template/gpt_structure.py"
    
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()
    
    # æ·»åŠ ä¸€ä¸ªæ–°çš„å®‰å…¨ç”Ÿæˆå“åº”å‡½æ•°ï¼Œä½¿ç”¨ ChatGPT
    if 'def safe_generate_response_chatgpt(' not in content:
        new_function = '''
def safe_generate_response_chatgpt(prompt, 
                                   max_tokens=50,
                                   temperature=0.5,
                                   repeat=5,
                                   fail_safe_response="error",
                                   func_validate=None,
                                   func_clean_up=None,
                                   verbose=False): 
  """
  ä½¿ç”¨ ChatGPT çš„å®‰å…¨å“åº”ç”Ÿæˆå‡½æ•°
  è¿™ä¸ªå‡½æ•°å°†æ—§çš„ GPT-3 å‚æ•°è½¬æ¢ä¸º ChatGPT è°ƒç”¨
  """
  if verbose: 
    print("ChatGPT PROMPT:")
    print(prompt)

  for i in range(repeat): 
    try:
      # ä½¿ç”¨ ChatGPT API
      completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=max_tokens,
        temperature=temperature
      )
      curr_gpt_response = completion["choices"][0]["message"]["content"].strip()
      
      if func_validate and func_validate(curr_gpt_response, prompt=prompt): 
        return func_clean_up(curr_gpt_response, prompt=prompt) if func_clean_up else curr_gpt_response
      elif not func_validate:
        return func_clean_up(curr_gpt_response, prompt=prompt) if func_clean_up else curr_gpt_response
        
      if verbose: 
        print(f"---- repeat count: {i}")
        print(curr_gpt_response)
        print("~~~~")

    except Exception as e:
      if verbose:
        print(f"Error in attempt {i}: {str(e)}")
      pass
  
  print("FAIL SAFE TRIGGERED") 
  return fail_safe_response

'''
        # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ æ–°å‡½æ•°
        content += new_function
    
    with open(file_path, 'w', encoding='utf-8') as file:
        file.write(content)
    
    print("âœ… å·²æ›´æ–° gpt_structure.py")

def fix_run_gpt_prompt():
    """ä¿®å¤ run_gpt_prompt.py ä¸­çš„æ‰€æœ‰ GPT è°ƒç”¨"""
    file_path = "/Users/gongyunbo/Documents/Github/generative_agents/reverie/backend_server/persona/prompt_template/run_gpt_prompt.py"
    
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()
    
    # 1. é¦–å…ˆæ·»åŠ å¯¼å…¥
    if 'from gpt_structure import safe_generate_response_chatgpt' not in content:
        import_line = 'from gpt_structure import *'
        if import_line in content:
            content = content.replace(import_line, import_line + '\\nfrom gpt_structure import safe_generate_response_chatgpt')
        else:
            # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥
            lines = content.split('\\n')
            for i, line in enumerate(lines):
                if line.startswith('from ') or line.startswith('import '):
                    lines.insert(i + 1, 'from gpt_structure import safe_generate_response_chatgpt')
                    break
            content = '\\n'.join(lines)
    
    # 2. æ›¿æ¢æ‰€æœ‰çš„ safe_generate_response è°ƒç”¨ä¸ºæ–°çš„å‡½æ•°
    # æŸ¥æ‰¾æ¨¡å¼ï¼šsafe_generate_response(prompt, gpt_param, 5, fail_safe, __func_validate, __func_clean_up)
    pattern = r'safe_generate_response\s*\(\s*prompt\s*,\s*gpt_param\s*,\s*(\d+)\s*,\s*([^,]+)\s*,\s*([^,]+)\s*,\s*([^)]+)\s*\)'
    
    def replace_function(match):
        repeat = match.group(1)
        fail_safe = match.group(2)
        func_validate = match.group(3)
        func_clean_up = match.group(4)
        
        return f'safe_generate_response_chatgpt(prompt, max_tokens=gpt_param.get("max_tokens", 50), temperature=gpt_param.get("temperature", 0.5), repeat={repeat}, fail_safe_response={fail_safe}, func_validate={func_validate}, func_clean_up={func_clean_up})'
    
    content = re.sub(pattern, replace_function, content)
    
    # 3. å¤„ç†å…¶ä»–æ¨¡å¼çš„ safe_generate_response è°ƒç”¨
    pattern2 = r'safe_generate_response\s*\(\s*prompt\s*,\s*gpt_param\s*,\s*(\d+)\s*,\s*([^,]+)\s*,\s*([^,]+)\s*,\s*([^,]+)\s*,\s*([^)]+)\s*\)'
    content = re.sub(pattern2, replace_function, content)
    
    # 4. æ³¨é‡Šæ‰æˆ–åˆ é™¤æ—§çš„ gpt_param å®šä¹‰ï¼ˆå¯é€‰ï¼‰
    # ä¿ç•™å®ƒä»¬ä»¥é˜²éœ€è¦å‚è€ƒå‚æ•°å€¼
    
    with open(file_path, 'w', encoding='utf-8') as file:
        file.write(content)
    
    print("âœ… å·²æ›´æ–° run_gpt_prompt.py")

def main():
    print("ğŸ”§ å¼€å§‹ä¿®å¤ TOKEN LIMIT EXCEEDED é—®é¢˜...")
    print("=" * 60)
    
    try:
        # 1. ä¿®å¤ gpt_structure.py
        fix_gpt_structure()
        
        # 2. ä¿®å¤ run_gpt_prompt.py  
        fix_run_gpt_prompt()
        
        print("=" * 60)
        print("ğŸ‰ ä¿®å¤å®Œæˆï¼")
        print("âœ… å·²å°†æ‰€æœ‰ text-davinci-003 è°ƒç”¨æ›¿æ¢ä¸º gpt-3.5-turbo")
        print("âœ… ç°åœ¨å¯ä»¥é‡æ–°è¿è¡Œä»¿çœŸäº†")
        
    except Exception as e:
        print(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        return False
    
    return True

if __name__ == "__main__":
    main()